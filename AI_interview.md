# NAVER_boostcamp_AITech_2nd_interview_question_AI
- Reference 이외의 질문들은 여러 면접시 직접 받은 중복되지 않은 질문들도 섞여있습니다. 

## AI
### [Deep Learning](https://github.com/sw6820/NAVER_boostcamp_AITech_2nd_interview_question/blob/main/AI/Topic/DL.md)
### [Machine Learning](https://github.com/sw6820/NAVER_boostcamp_AITech_2nd_interview_question/blob/main/AI/Topic/ML.md)
### [CV](https://github.com/sw6820/NAVER_boostcamp_AITech_2nd_interview_question/blob/main/AI/Topic/CV.md)
### [NLP](https://github.com/sw6820/NAVER_boostcamp_AITech_2nd_interview_question/blob/main/AI/Topic/NLP.md)
### [Reinforce Learning](https://github.com/sw6820/NAVER_boostcamp_AITech_2nd_interview_question/blob/main/AI/Topic/RL.md)
### [Recommender System](https://github.com/sw6820/NAVER_boostcamp_AITech_2nd_interview_question/blob/main/AI/Topic/RS.md)
### [MLOps](https://github.com/sw6820/NAVER_boostcamp_AITech_2nd_interview_question/blob/main/AI/Topic/MLOps.md)
### [Statistics / Math](https://github.com/sw6820/NAVER_boostcamp_AITech_2nd_interview_question/blob/main/AI/Topic/Statistics_Math.md)

### Machine Learning
- 알고 있는 metric에 대해 설명해주세요. (ex. RMSE, MAE, recall, precision ...)
    - Precision
    - Recall
    - F1 score
- 정규화를 왜 해야할까요? 정규화의 방법은 무엇이 있나요?
- Local Minima와 Global Minima에 대해 설명해주세요.
- 차원의 저주에 대해 설명해주세요.
- dimension reduction기법으로 보통 어떤 것들이 있나요?
- PCA는 차원 축소 기법이면서, 데이터 압축 기법이기도 하고, 노이즈 제거기법이기도 합니다. 왜 그런지 설명해주실 수 있나요?
    - PCA에서 components의 회전이 중요한 이유
- LSA, LDA, SVD 등의 약자들이 어떤 뜻이고 서로 어떤 관계를 가지는지 설명할 수 있나요?
- Markov Chain을 고등학생에게 설명하려면 어떤 방식이 제일 좋을까요?
- 텍스트 더미에서 주제를 추출해야 합니다. 어떤 방식으로 접근해 나가시겠나요?
- SVM은 왜 반대로 차원을 확장시키는 방식으로 동작할까요? SVM은 왜 좋을까요?
- 다른 좋은 머신 러닝 대비, 오래된 기법인 나이브 베이즈(naive bayes)의 장점을 옹호해보세요.
- 회귀 / 분류시 알맞은 metric은 무엇일까?
- Association Rule의 Support, Confidence, Lift에 대해 설명해주세요.
- 최적화 기법중 Newton’s Method와 Gradient Descent 방법에 대해 알고 있나요?
- 머신러닝(machine)적 접근방법과 통계(statistics)적 접근방법의 둘간에 차이에 대한 견해가 있나요?
- 인공신경망(deep learning이전의 전통적인)이 가지는 일반적인 문제점은 무엇일까요?
- 지금 나오고 있는 deep learning 계열의 혁신의 근간은 무엇이라고 생각하시나요?
- ROC 커브에 대해 설명해주실 수 있으신가요?
- 여러분이 서버를 100대 가지고 있습니다. 이때 인공신경망보다 Random Forest를 써야하는 이유는 뭘까요?
- K-means의 대표적 의미론적 단점은 무엇인가요? (계산량 많다는것 말고)
- L1, L2 정규화에 대해 설명해주세요.
- Cross Validation은 무엇이고 어떻게 해야하나요?
- XGBoost을 아시나요? 왜 이 모델이 캐글에서 유명할까요?
- 앙상블 방법엔 어떤 것들이 있나요?
- feature vector란 무엇일까요?tj
- 좋은 모델의 정의는 무엇일까요?
- 50개의 작은 의사결정 나무는 큰 의사결정 나무보다 괜찮을까요? 왜 그렇게 생각하나요?
- 스팸 필터에 로지스틱 리그레션을 많이 사용하는 이유는 무엇일까요?
- OLS(ordinary least squre) regression의 공식은 무엇인가요?
- ML 도입 이유
- 지도학습 vs 비지도학습 vs 강화학습
    - 지도학습
    - 비지도학습
    - 강화학습
- Bayes'Theorem?
- Naive bayes?
    - Naive bayes 에서 Naive는?
- PCA를 쓰는 경우
- SVM 알고리즘 자세히 설명하시오
    - SVM에서 support vectors가 무엇인가
- Cross-Validataion 이 무엇인가?
- ML에서 Bias는 무엇인가?
- Classification vs Regression
- F1 score가 뭔가? 어떻게 쓰나?
- Precision & Recall 정의
- Overfitting & Underfitting 대처법
- 인공 신경망이 무엇인가
- Loss Function & Cost function 정의, 차이점
- Ensemble Learning이 무엇인가?
- 어느 ML 알고리즘을 사용할지 어떻게 확신하나
- Outlier?
    - Outlier Values를 어떻게 다루나
- Random Forest 정의, 작동 방식
- K-means Clustering에서 K를 어떻게 고르나
- dataset의 Normality를 확인하는 방법
- Logistic Regression을 2가지 이상의 클래스에 사용 가능한가?
- Correlation vs Covariance vs Casuality
- Parametric & Non-Parametric 모델 설명
- 강화학습이 뭔가?
- Sigmoid vs Softmax 
- time series는 무엇인가요?
- box-cow transformation?
- random forest vs gradient boosting
- confusion matrix? 왜 
- marginalization?
    - marginalization 의 process
- data의 outliers를 다루는 방법
- 유명한 cross validation 기술들?
- Fixed Basis Function의 한계
- EDA technique
- boosting vs bagging
- ROC Curve
- Water Trapping Problem
- Decision tree 에서 hyper-parameter는?
- Cross-Validation의 역할?
- Pandas Profiling
- KNN에서 사용되는 거리 metric?
- pipeline이 무엇인가
- pruning의 이점
- the degree of freedom?
- Type I and Type II error
- utilities fraud detection에 관한 dataset이 있을때, 분류모델을 만들었고 그 모델 성능이 98.5%를 달성했을 때, 좋은 모델인가? 그렇다면 정당화하고, 아니라면 무엇을 할 수 있을까?
- 주어진 dataset에서 missing value나 corrupted value를 다루는 방법?
- How do you select important variables while working on a data set? 
- dataset이 주어졌을 때 사용할 ML 알고리즘을 고르는 방법?
- Hardware에 ML을 적용하는 방법 
- A data set is given to you and it has missing values which spread along 1 standard deviation from the mean. How much of the data would remain untouched?
- Stochastic Gradient Descent(SGD) vs Gradient Descent(GD)?
- 역전파 사용시 exploding gradient problem은?
- decision tree의 장단점

## Reference
- https://360digitmg.com/mlops-interview-questions-answers
- https://github.com/zzsza/Datascience-Interview-Questions?fbclid=IwAR1sVmRVTTRq73bwxHriYNyxDJG5mJzmtjQB01-jh16OefLFJCQsCyp7lf8
- https://github.com/boostcamp-ai-tech-4/ai-tech-interview
- https://www.mlstack.cafe/interview-questions/recommendation-systems
- https://www.mlstack.cafe/blog/recommendation-systems-interview-questions
- https://datascience.stackexchange.com/questions/tagged/recommender-system
- https://www.interviewbit.com/machine-learning-interview-questions/
- https://www.mygreatlearning.com/blog/machine-learning-interview-questions/
- https://www.springboard.com/blog/ai-machine-learning/machine-learning-interview-questions/
